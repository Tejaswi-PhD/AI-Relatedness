{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Define folder path and keyword lists\n",
    "submission_folder_path = \"10k_submissions\"\n",
    "\n",
    "value_creation_keywords_raw = [\n",
    "    \"ability\", \"accelerate\", \"acceleration\", \"activism\", \"aggrandizement\", \"agile\", \"agility\", \"ahead time\", \"aimed\", \"anew\", \"arise\", \"aspirations\", \"attack\", \"brand new\",\n",
    "    \"break ground\", \"bring to being\", \"bring to existence\", \"bring forth\", \"bring forward\", \"bring to life\", \"bring to light\", \"bring out\", \"bring pass\", \"bring to public\", \"bring to the world\", \"build\", \"call to existence\", \"change\",\n",
    "    \"commodities\", \"completion\", \"compose\", \"concept\", \"conceptual\", \"configuration\", \"constitute\", \"construed\", \"contrive\", \"create\", \"creation\",\n",
    "    \"creative\", \"creativity\", \"curious\", \"deliver\", \"deliverability\", \"deliverable\", \"demand driven\", \"demand side\", \"demonstrate\", \"demonstration\", \"deploy\", \"detect\",\n",
    "    \"detection\", \"develop\", \"development\", \"discover\", \"discovery\", \"draft\", \"draw up\", \"dream\", \"early adopted\", \"emerge\", \"emergence\", \"engender\",\n",
    "    \"engenderment\", \"engine\", \"engineer\", \"enrichment\", \"establish\", \"establishment\", \"evolution\", \"evolutionary\", \"evolve\", \"exceptional\", \"experimental\",\n",
    "    \"experimentation\", \"explore\", \"exploration\", \"fabricate\", \"fabrication\", \"facilitate\", \"facilitation\", \"factory\", \"feasible\", \"first move\", \"first step\", \"forge\", \"form\",\n",
    "    \"founded\", \"founder\", \"from beginning\", \"from ground\", \"from scratch\", \"fructify\", \"funded\", \"funding\", \"furnish\", \"generate\", \"give life\", \"give rise\", \"grow better\", \"growth\",\n",
    "    \"heighten\", \"high value\", \"idea\", \"incept\", \"inception\", \"increase\", \"initial\", \"initiate\", \"initiation\", \"initiative\", \"innovate\", \"innovation\", \"innovation driven\",\n",
    "    \"invent\", \"invention\", \"investment\", \"laboratory\", \"lifting\", \"made\", \"magnify\", \"make changes\", \"manufacture\", \"market based\",\n",
    "    \"modernize\", \"modernization\", \"newborn\", \"newer\", \"newly arrived\", \"newly come\", \"newly issued\", \"novation\", \"novel\", \"novelty\", \"opening\", \"preparation\", \"proclaim\",\n",
    "    \"procreate\", \"procreation\", \"produce\", \"production\", \"product related\", \"productive\", \"productivity\", \"progress\", \"progression\", \"promised results\",\n",
    "    \"prototype\", \"prototyping\", \"pursuit\", \"quest\", \"raise\", \"realizable\", \"realize\", \"realization\", \"rebuild\", \"recent make\", \"recent period\", \"re-create\", \"re-develop\",\n",
    "    \"reinvent\", \"remake\", \"research\", \"revolution\", \"revolutionary\", \"revolutionize\", \"roadmap\", \"search\", \"shape\", \"sift through\", \"sifting\", \"solution\", \"spark\", \"speed up\",\n",
    "    \"strengthen\", \"study\", \"transform\", \"transformation\", \"trendy\", \"ultramodern\", \"unexplored\", \"unfolding\", \"up to date\", \"useful\", \"value added\", \"vision\",\n",
    "    \"work out\"\n",
    "]\n",
    "\n",
    "value_appropriation_keywords_raw = [\n",
    "    \"ablation\", \"adapt\", \"adaptation\", \"addition\", \"additives\", \"additory\", \"adjudication\", \"adjust\", \"adjustment\", \"adopt\", \"adoption\", \"advance\",\n",
    "    \"advancement\", \"advantage\", \"advertise\", \"advertising\", \"advertisement\", \"advertorial\", \"affiliate\", \"affiliation\", \"allocate\",\n",
    "    \"allocation\", \"allotment\", \"alter\", \"alteration\", \"ameliorate\", \"amelioration\", \"amend\", \"amendment\", \"augment\", \"augmentation\", \"aware\",\n",
    "    \"awareness\", \"behoove\", \"beneficial\", \"benefit\", \"benefit expense\", \"benefit related\", \"big name\", \"brand\", \"brand building\", \"branded\",\n",
    "    \"branding\", \"brand loyalty\", \"brand name\", \"broadcast\", \"broaden\", \"capacities\", \"capital out\", \"capitalize\", \"capture\", \"carry\", \"carry forward\",\n",
    "    \"certificate\", \"certify\", \"challenge\", \"coexist\", \"collect\", \"commerce\", \"commercial\", \"commercialize\",\n",
    "    \"commercialization\", \"competition\", \"compete\", \"competitive\", \"competitiveness\", \"consideration\", \"consolidate\", \"consolidation\",\n",
    "    \"contest\", \"continual\", \"continuance\", \"continuation\", \"contribute\", \"contribution\", \"convert\", \"conversion\", \"conversion rate\", \"convertibility\",\n",
    "    \"cost effective\", \"cost efficient\", \"cost saving\", \"customer centric\", \"customer driven\", \"customer facing\", \"customer focused\", \"customer loyalty\", \"customer oriented\", \"customer pleasing\", \"customer specific\", \"customize\",\n",
    "    \"customization\", \"defend\", \"defense\", \"demarcation\", \"derive\", \"detail\", \"differentiate\", \"differentiation\", \"differ\", \"direct mail\",\n",
    "    \"discriminate\", \"discrimination\", \"distinct\", \"distinction\", \"distinguish\", \"diversity\", \"earn\", \"earnings\", \"efficacy\", \"elaborate\", \"embedding\",\n",
    "    \"emphasize\", \"emphasis\", \"endorse\", \"endorsement\", \"engage\", \"engagement\", \"enhance\", \"enhancement\", \"evoke\", \"expand\", \"expansion\",\n",
    "    \"exploit\", \"exploitation\", \"extension\", \"extract\", \"extraction\", \"feature\", \"franchise\", \"gain\", \"gain strength\", \"glean\", \"glory\", \"harvesting\",\n",
    "    \"hedge\", \"improve\", \"improvement\", \"income\", \"increment\", \"individualize\", \"influence\", \"isolate\", \"isolation\", \"joint venture\", \"justify\",\n",
    "    \"label\", \"learn\", \"leverage\", \"license\", \"licensing\", \"lift\", \"loyalty\", \"make better\", \"make good\", \"make most\", \"higher margin\", \"margin\", \"marketed\", \"marketing\",\n",
    "    \"marketing related\", \"market leading\", \"maximize\", \"maximum\", \"meliorate\", \"newly modify\", \"modify\", \"modification\", \"monetize\", \"monetization\",\n",
    "    \"multichannel\", \"newspaper ad\", \"optimize\", \"outcome\", \"outperform\", \"outperformance\", \"outsourcing\", \"patent\", \"payoff\", \"payor\",\n",
    "    \"perform\", \"performance\", \"permit\", \"popularity\", \"position\", \"prefer\", \"preferable\", \"premium\", \"prestige\", \"procedure\", \"proceed\",\n",
    "    \"process\", \"profit from\", \"profit gains\", \"profitability\", \"prominence\", \"promote\",\n",
    "    \"promotion\", \"promulgated\", \"protect\", \"protection\", \"publicity\", \"reallocate\",\n",
    "    \"reallocation\", \"rebrand\", \"recognition\", \"recognizable\", \"reconsider\", \"reconsideration\", \"reconstruct\", \"redefine\", \"redevelopments\",\n",
    "    \"refine\", \"refocused\", \"refreshed\", \"registered trademark\", \"reinvesting\", \"renovate\", \"reorganize\", \"representation\", \"reputation\",\n",
    "    \"revenue\", \"revenue generating\", \"rewarding\", \"rights reserved\", \"segmentation\", \"service\", \"serviceableness\", \"standalone\", \"standardize\",\n",
    "    \"status\", \"stronghold\", \"submarket\", \"substitutable\", \"substituting\", \"superior\", \"superiority\", \"support\",\n",
    "    \"supportive\", \"take advantage of\", \"trade name\", \"trademark\", \"uplift\", \"usefulness\", \"utilize\", \"valuations\"\n",
    "]\n",
    "\n",
    "# Pre-compute average embeddings for VC/VA lists\n",
    "print(\"Pre-computing embeddings for VC keywords...\")\n",
    "vc_keyword_embeddings = embedding_model.encode(value_creation_keywords_raw, show_progress_bar=True)\n",
    "avg_vc_embedding = np.mean(vc_keyword_embeddings, axis=0)\n",
    "\n",
    "print(\"Pre-computing embeddings for VA keywords...\")\n",
    "va_keyword_embeddings = embedding_model.encode(value_appropriation_keywords_raw, show_progress_bar=True)\n",
    "avg_va_embedding = np.mean(va_keyword_embeddings, axis=0)\n",
    "\n",
    "# Helper function for document embedding\n",
    "def compute_document_embedding(text, model, chunk_size=256):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk_sentences = []\n",
    "    current_chunk_word_count = 0\n",
    "\n",
    "    if not text.strip():\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "\n",
    "    for sentence in sentences:\n",
    "        token_count = len(word_tokenize(sentence))\n",
    "        if current_chunk_word_count + token_count > chunk_size and current_chunk_sentences:\n",
    "            chunks.append(\" \".join(current_chunk_sentences))\n",
    "            current_chunk_sentences = [sentence]\n",
    "            current_chunk_word_count = token_count\n",
    "        else:\n",
    "            current_chunk_sentences.append(sentence)\n",
    "            current_chunk_word_count += token_count\n",
    "    \n",
    "    if current_chunk_sentences:\n",
    "        chunks.append(\" \".join(current_chunk_sentences))\n",
    "    \n",
    "    if not chunks:\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "\n",
    "    chunk_embeddings = model.encode(chunks, batch_size=32, show_progress_bar=False)\n",
    "    return np.mean(chunk_embeddings, axis=0)\n",
    "\n",
    "# Main processing function\n",
    "def process_10k_files_for_vc_va_embeddings(folder_path):\n",
    "    results = []\n",
    "    \n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise FileNotFoundError(f\"Folder not found: {folder_path}\")\n",
    "    \n",
    "    files_to_process = [f for f in os.listdir(folder_path) if f.lower().endswith(\".txt\")]\n",
    "    if not files_to_process:\n",
    "        raise FileNotFoundError(f\"No .txt files in: {folder_path}\")\n",
    "\n",
    "    print(f\"Found {len(files_to_process)} .txt files to process.\")\n",
    "\n",
    "    for filename in tqdm(files_to_process, desc=\"Processing files\"):\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        parts = base_name.split('_')\n",
    "        cik = parts[0]\n",
    "        year_suffix = parts[1]\n",
    "        year = f\"20{year_suffix}\" if len(year_suffix) == 2 else year_suffix\n",
    "        \n",
    "        with open(os.path.join(folder_path, filename), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            raw_text = f.read()\n",
    "\n",
    "        doc_embedding = (compute_document_embedding(raw_text, embedding_model)\n",
    "                         if raw_text.strip()\n",
    "                         else np.zeros(embedding_model.get_sentence_embedding_dimension()))\n",
    "        vc_score = cosine_similarity([doc_embedding], [avg_vc_embedding])[0][0] * 100 if np.any(doc_embedding) else 0.0\n",
    "        va_score = cosine_similarity([doc_embedding], [avg_va_embedding])[0][0] * 100 if np.any(doc_embedding) else 0.0\n",
    "        \n",
    "        results.append({\n",
    "            \"CIK\": cik,\n",
    "            \"Year\": year,\n",
    "            \"Filename\": filename,\n",
    "            \"VC_Embedding_Score (%)\": vc_score,\n",
    "            \"VA_Embedding_Score (%)\": va_score,\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Execute processing\n",
    "df_vc_va = process_10k_files_for_vc_va_embeddings(submission_folder_path)\n",
    "df_vc_va.to_csv(\"vc_va_embedding_scores.csv\", index=False)\n",
    "df_vc_va.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
